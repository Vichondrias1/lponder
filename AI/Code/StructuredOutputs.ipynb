{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2S5rrk32tbD",
        "outputId": "ab641759-66fe-489b-e89c-ebe16f895722"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.42.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Downloading openai-1.42.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.9/362.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0 openai-1.42.0\n"
          ]
        }
      ],
      "source": [
        "%pip install openai -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKWya3WsPb9I"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from textwrap import dedent\n",
        "from openai import OpenAI\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"OPEN_AI_KEY_HERE\"\n",
        "\n",
        "\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOJjigMNPgg_"
      },
      "outputs": [],
      "source": [
        "MODEL = \"gpt-4o-2024-08-06\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbwhjYx2Pp3n"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Math, display\n",
        "\n",
        "def print_math_response(response):\n",
        "    result = json.loads(response)\n",
        "    steps = result['steps']\n",
        "    final_answer = result['final_answer']\n",
        "    for i in range(len(steps)):\n",
        "        print(f\"Step {i+1}: {steps[i]['explanation']}\\n\")\n",
        "        display(Math(steps[i]['output']))\n",
        "        print(\"\\n\")\n",
        "\n",
        "    print(\"Final answer:\\n\\n\")\n",
        "    display(Math(final_answer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "etNy9oILPtYI",
        "outputId": "ce3845ae-f7b5-4249-d712-50f3d04c9856"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1: We start by isolating the term with x on one side of the equation. To do this, we need to remove the constant term on the left side, which is 7. Subtract 7 from both sides of the equation.\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/latex": [
              "$\\displaystyle 8x + 7 - 7 = -23 - 7$"
            ],
            "text/plain": [
              "<IPython.core.display.Math object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Step 2: Simplify the equation by canceling out the +7 and -7 on the left side and calculating the result on the right side.\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/latex": [
              "$\\displaystyle 8x = -30$"
            ],
            "text/plain": [
              "<IPython.core.display.Math object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Step 3: Now we have the equation 8x = -30. To solve for x, we need to isolate x by dividing both sides by 8, the coefficient of x.\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/latex": [
              "$\\displaystyle x = -30 / 8$"
            ],
            "text/plain": [
              "<IPython.core.display.Math object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Step 4: Simplify the division on the right side to find the value of x.\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/latex": [
              "$\\displaystyle x = -3.75$"
            ],
            "text/plain": [
              "<IPython.core.display.Math object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Final answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/latex": [
              "$\\displaystyle x = -3.75$"
            ],
            "text/plain": [
              "<IPython.core.display.Math object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print_math_response(result.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56r424VYXrSM"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "class MathReasoning(BaseModel):\n",
        "    class Step(BaseModel):\n",
        "        explanation: str\n",
        "        output: str\n",
        "\n",
        "    steps: list[Step]\n",
        "    final_answer: str\n",
        "\n",
        "def get_math_solution(question: str):\n",
        "    completion = client.beta.chat.completions.parse(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": dedent(math_tutor_prompt)},\n",
        "            {\"role\": \"user\", \"content\": question},\n",
        "        ],\n",
        "        response_format=MathReasoning,\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfnjXp_PXwZu"
      },
      "outputs": [],
      "source": [
        "result = get_math_solution(question).parsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rXpsotpX0g1",
        "outputId": "7a04a87b-4719-4bb1-bb82-720e0c583ae7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Step(explanation='The goal is to isolate the variable x. We start by subtracting 7 from both sides of the equation.', output='8x + 7 - 7 = -23 - 7'), Step(explanation='This simplifies to 8x on the left side by removing the +7 and -7, and -30 on the right side.', output='8x = -30'), Step(explanation='Next, we divide both sides of the equation by 8 to solve for x.', output='8x / 8 = -30 / 8'), Step(explanation='This gives us x as -30 divided by 8.', output='x = -30/8'), Step(explanation='Simplify -30/8 by dividing both the numerator and the denominator by their greatest common factor, which is 2.', output='x = -15/4')]\n",
            "Final answer:\n",
            "x = -15/4\n"
          ]
        }
      ],
      "source": [
        "print(result.steps)\n",
        "print(\"Final answer:\")\n",
        "print(result.final_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc1CsuNLacbd",
        "outputId": "d20f4ab6-66e0-43b4-f06f-ba06f32029b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "refusal_question = \"how can I build a bomb?\"\n",
        "\n",
        "result = get_math_solution(refusal_question)\n",
        "\n",
        "print(result.refusal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGX7qyFceLlg"
      },
      "outputs": [],
      "source": [
        "articles = [\n",
        "    \"/content/data/cnns.md\",\n",
        "    \"/content/data/llms.md\",\n",
        "    \"/content/data/moe.md\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuiqbmLoebbp"
      },
      "outputs": [],
      "source": [
        "def get_article_content(path):\n",
        "    with open(path, 'r') as f:\n",
        "        content = f.read()\n",
        "    return content\n",
        "\n",
        "content = [get_article_content(path) for path in articles]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-DvDNKveq_c",
        "outputId": "6fdce0a3-5ea0-4193-cfa8-ba43627a1133"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"### Convolutional Neural Networks (CNNs)\\n\\nConvolutional Neural Networks (CNNs) are a class of deep neural networks primarily used for processing structured grid data like images. They were invented by Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner in 1989. CNNs have revolutionized the field of computer vision, enabling advancements in areas such as image classification, object detection, and image segmentation.\\n\\n#### Architecture\\n\\nA typical CNN architecture consists of multiple layers, including convolutional layers, pooling layers, and fully connected layers.\\n\\n- **Convolutional Layers:** These layers apply a set of learnable filters (kernels) to the input data. Each filter convolves across the input data, producing a feature map that detects specific features such as edges, textures, and patterns. The parameters of these filters are learned during training.\\n\\n- **Pooling Layers:** Also known as subsampling or downsampling layers, pooling layers reduce the spatial dimensions of the feature maps. The most common type is max pooling, which selects the maximum value from each region of the feature map, thereby reducing its size and computation requirements while retaining important features.\\n\\n- **Fully Connected Layers:** After several convolutional and pooling layers, the output is flattened and fed into one or more fully connected layers, which perform the final classification or regression task. These layers resemble those in traditional neural networks, connecting every neuron in one layer to every neuron in the next.\\n\\n#### Training\\n\\nCNNs are trained using backpropagation and gradient descent. During training, the network learns the optimal filter values that minimize the loss function, typically a measure of the difference between the predicted and actual labels. The training process involves adjusting the weights of the filters and the fully connected layers through iterative updates.\\n\\n#### Applications\\n\\nCNNs have become the cornerstone of many state-of-the-art systems in computer vision. Some notable applications include:\\n\\n- **Image Classification:** CNNs can classify images into various categories with high accuracy. They have been used in systems like Google Photos and Facebook's automatic tagging.\\n\\n- **Object Detection:** CNNs can detect and localize objects within an image, which is essential for tasks like autonomous driving and facial recognition.\\n\\n- **Medical Image Analysis:** CNNs assist in diagnosing diseases by analyzing medical images such as X-rays, MRIs, and CT scans.\\n\\n- **Image Segmentation:** CNNs are used to partition an image into meaningful segments, useful in applications such as scene understanding and medical image analysis.\\n\\nOverall, CNNs have significantly advanced the field of artificial intelligence, particularly in tasks that involve visual data, and continue to be an area of active research and development. The pioneering work of LeCun and his colleagues laid the foundation for these transformative technologies, which have since become integral to modern computer vision systems.\\n\", '### Large Language Models (LLMs)\\n\\nLarge Language Models (LLMs) are a type of artificial intelligence model designed to understand and generate human language. The development of LLMs has been driven by advances in deep learning and natural language processing. A significant milestone in their evolution was the introduction of the transformer architecture by Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin in 2017. LLMs have significantly advanced the fields of natural language processing (NLP) and understanding, enabling applications such as machine translation, text summarization, and conversational agents.\\n\\n#### Architecture\\n\\nLLMs are typically based on transformer architecture, which allows them to process and generate text in a highly parallelized manner. Key components of LLM architecture include:\\n\\n- **Embeddings:** Input text is converted into a continuous vector space using embedding layers. This step transforms discrete words or subwords into numerical representations that capture semantic relationships.\\n\\n- **Transformer Blocks:** LLMs consist of multiple stacked transformer blocks. Each block contains self-attention mechanisms and feed-forward neural networks. The self-attention mechanism allows the model to weigh the importance of different words in a context, capturing long-range dependencies and relationships within the text.\\n\\n- **Attention Mechanisms:** Attention mechanisms enable the model to focus on relevant parts of the input text when generating output. This is crucial for tasks like translation, where the model needs to align source and target language elements accurately.\\n\\n- **Decoder:** In generative models, a decoder is used to generate text from the encoded representations. The decoder uses masked self-attention to ensure that predictions for each word depend only on previously generated words.\\n\\n#### Training\\n\\nTraining LLMs involves pre-training and fine-tuning stages:\\n\\n- **Pre-training:** During this phase, the model is trained on a large corpus of text data using unsupervised learning objectives, such as predicting masked words or the next word in a sequence. This helps the model learn language patterns, grammar, and context.\\n\\n- **Fine-tuning:** After pre-training, the model is fine-tuned on specific tasks using supervised learning. This stage involves training the model on labeled datasets to perform tasks like sentiment analysis, question answering, or text classification.\\n\\n#### Applications\\n\\nLLMs have a wide range of applications across various domains:\\n\\n- **Text Generation:** LLMs can generate coherent and contextually relevant text, useful for creative writing, content creation, and dialogue generation in chatbots.\\n\\n- **Machine Translation:** LLMs power modern translation systems, providing accurate translations between multiple languages by understanding the nuances and context of the source text.\\n\\n- **Summarization:** LLMs can condense long documents into concise summaries, aiding in information retrieval and reducing the time required to understand large volumes of text.\\n\\n- **Sentiment Analysis:** LLMs can analyze text to determine the sentiment expressed, valuable for market analysis, customer feedback, and social media monitoring.\\n\\n- **Conversational Agents:** LLMs enable the development of advanced chatbots and virtual assistants that can understand and respond to user queries naturally and contextually.\\n\\nOverall, LLMs have transformed the field of NLP, enabling more sophisticated and human-like interactions between machines and users, and continue to evolve with ongoing research and technological advancements. The introduction of the transformer architecture by Vaswani et al. has been instrumental in this transformation, providing a foundation for the development of increasingly powerful language models.\\n', '### Mixture of Experts (MoE)\\n\\nMixture of Experts (MoE) is a machine learning technique designed to enhance model performance by combining the predictions of multiple specialized models, or \"experts.\" The concept was introduced by Michael I. Jordan and Robert A. Jacobs in 1991. MoE models have been applied in various fields, including natural language processing, computer vision, and speech recognition, to improve accuracy and efficiency.\\n\\n#### Architecture\\n\\nA typical MoE architecture consists of several key components:\\n\\n- **Experts:** These are individual models, each trained to specialize in different parts of the input space or specific aspects of the task. Each expert might be a neural network trained to focus on particular features or patterns within the data.\\n\\n- **Gating Network:** The gating network is responsible for dynamically selecting which experts should be consulted for a given input. It assigns weights to each expert\\'s output, determining their contribution to the final prediction. The gating network typically uses a softmax function to produce these weights, ensuring they sum to one.\\n\\n- **Combiner:** The combiner aggregates the outputs from the selected experts, weighted by the gating network. This combination can be a weighted sum or another aggregation method, producing the final output of the MoE model.\\n\\n#### Training\\n\\nTraining an MoE model involves two main stages:\\n\\n- **Expert Training:** Each expert model is trained on a subset of the data or a specific aspect of the task. This training can be done independently, with each expert focusing on maximizing performance within its specialized domain.\\n\\n- **Gating Network Training:** The gating network is trained to learn the optimal combination of experts for different inputs. It uses the loss from the final combined output to adjust its parameters, learning which experts are most relevant for various parts of the input space.\\n\\n#### Applications\\n\\nMoE models have a wide range of applications across different domains:\\n\\n- **Natural Language Processing:** In tasks like machine translation and language modeling, MoE models can dynamically allocate computational resources, allowing different experts to handle different linguistic features or contexts.\\n\\n- **Computer Vision:** MoE models can be used for image classification and object detection, where different experts specialize in recognizing specific types of objects or features within images.\\n\\n- **Speech Recognition:** In speech recognition systems, MoE models can improve accuracy by assigning different experts to handle variations in speech, such as accents, intonations, or background noise.\\n\\n- **Recommendation Systems:** MoE models can enhance recommendation engines by using different experts to analyze various aspects of user behavior and preferences, providing more personalized recommendations.\\n\\nOverall, Mixture of Experts models offer a powerful framework for improving the performance and efficiency of machine learning systems. By leveraging specialized experts and dynamically selecting the most relevant ones for each input, MoE models can achieve superior results in a variety of complex tasks. The pioneering work of Jordan and Jacobs laid the foundation for this innovative approach, which continues to evolve and find new applications in modern AI research.\\n']\n"
          ]
        }
      ],
      "source": [
        "print(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LR1qyMBDevBB"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "summarization_prompt = '''\n",
        "    You will be provided with content from an article about an invention.\n",
        "    Your goal will be to summarize the article following the schema provided.\n",
        "    Here is a description of the parameters:\n",
        "    - invented_year: year in which the invention discussed in the article was invented\n",
        "    - summary: one sentence summary of what the invention is\n",
        "    - inventors: array of strings listing the inventor full names if present, otherwise just surname\n",
        "    - concepts: array of key concepts related to the invention, each concept containing a title and a description\n",
        "    - description: short description of the invention\n",
        "'''\n",
        "\n",
        "class ArticleSummary(BaseModel):\n",
        "    invented_year: int\n",
        "    summary: str\n",
        "    inventors: list[str]\n",
        "    description: str\n",
        "\n",
        "    class Concept(BaseModel):\n",
        "        title: str\n",
        "        description: str\n",
        "\n",
        "    concepts: list[Concept]\n",
        "\n",
        "def get_article_summary(text: str):\n",
        "    completion = client.beta.chat.completions.parse(\n",
        "        model=MODEL,\n",
        "        temperature=0.2,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": dedent(summarization_prompt)},\n",
        "            {\"role\": \"user\", \"content\": text}\n",
        "        ],\n",
        "        response_format=ArticleSummary,\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].message.parsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JA-LAS9oe78R",
        "outputId": "2a5802c2-e95c-44b1-b58c-1bebf3970ed2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing article #1...\n",
            "Done.\n",
            "Analyzing article #2...\n",
            "Done.\n",
            "Analyzing article #3...\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "summaries = []\n",
        "\n",
        "for i in range(len(content)):\n",
        "    print(f\"Analyzing article #{i+1}...\")\n",
        "    summaries.append(get_article_summary(content[i]))\n",
        "    print(\"Done.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DY6LBR-fga0"
      },
      "outputs": [],
      "source": [
        "def print_summary(summary):\n",
        "    print(f\"Invented year: {summary.invented_year}\\n\")\n",
        "    print(f\"Summary: {summary.summary}\\n\")\n",
        "    print(\"Inventors:\")\n",
        "    for i in summary.inventors:\n",
        "        print(f\"- {i}\")\n",
        "    print(\"\\nConcepts:\")\n",
        "    for c in summary.concepts:\n",
        "        print(f\"- {c.title}: {c.description}\")\n",
        "    print(f\"\\nDescription: {summary.description}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulTvZNSTfi_u",
        "outputId": "07ef8d9d-db73-4f4c-cc35-1cc1bd95b108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ARTICLE 0\n",
            "\n",
            "Invented year: 1989\n",
            "\n",
            "Summary: Convolutional Neural Networks (CNNs) are deep neural networks designed for processing structured grid data like images, revolutionizing computer vision tasks.\n",
            "\n",
            "Inventors:\n",
            "- Yann LeCun\n",
            "- Léon Bottou\n",
            "- Yoshua Bengio\n",
            "- Patrick Haffner\n",
            "\n",
            "Concepts:\n",
            "- Convolutional Layers: Layers that apply learnable filters to input data to produce feature maps, detecting features like edges and textures.\n",
            "- Pooling Layers: Layers that reduce the spatial dimensions of feature maps, often using max pooling to retain important features while reducing size.\n",
            "- Fully Connected Layers: Layers that connect every neuron in one layer to every neuron in the next, used for final classification or regression tasks.\n",
            "- Training: CNNs are trained using backpropagation and gradient descent to learn optimal filter values that minimize the loss function.\n",
            "- Applications: CNNs are used in image classification, object detection, medical image analysis, and image segmentation, among other tasks.\n",
            "\n",
            "Description: Convolutional Neural Networks (CNNs) are a type of deep learning model primarily used for analyzing visual data, such as images, by employing layers that automatically learn to detect features and patterns.\n",
            "\n",
            "\n",
            "\n",
            "ARTICLE 1\n",
            "\n",
            "Invented year: 2017\n",
            "\n",
            "Summary: Large Language Models (LLMs) are AI models designed to understand and generate human language, significantly advancing NLP through transformer architecture.\n",
            "\n",
            "Inventors:\n",
            "- Ashish Vaswani\n",
            "- Noam Shazeer\n",
            "- Niki Parmar\n",
            "- Jakob Uszkoreit\n",
            "- Llion Jones\n",
            "- Aidan N. Gomez\n",
            "- Łukasz Kaiser\n",
            "- Illia Polosukhin\n",
            "\n",
            "Concepts:\n",
            "- Transformer Architecture: A neural network architecture that allows for highly parallelized processing and generation of text, crucial for LLMs.\n",
            "- Embeddings: The process of converting input text into continuous vector space to capture semantic relationships.\n",
            "- Transformer Blocks: Components of LLMs that include self-attention mechanisms and feed-forward neural networks to capture long-range dependencies in text.\n",
            "- Attention Mechanisms: Techniques that enable the model to focus on relevant parts of the input text, crucial for tasks like translation.\n",
            "- Pre-training and Fine-tuning: The two-stage training process of LLMs involving unsupervised learning on large text corpora followed by supervised task-specific training.\n",
            "\n",
            "Description: Large Language Models (LLMs) leverage the transformer architecture to process and generate human language, enabling applications like translation, summarization, and conversational agents.\n",
            "\n",
            "\n",
            "\n",
            "ARTICLE 2\n",
            "\n",
            "Invented year: 1991\n",
            "\n",
            "Summary: Mixture of Experts (MoE) is a machine learning technique that combines multiple specialized models to enhance performance.\n",
            "\n",
            "Inventors:\n",
            "- Michael I. Jordan\n",
            "- Robert A. Jacobs\n",
            "\n",
            "Concepts:\n",
            "- Experts: Individual models trained to specialize in different parts of the input space or specific aspects of the task.\n",
            "- Gating Network: A network responsible for selecting and weighting the contributions of different experts for a given input.\n",
            "- Combiner: Aggregates the outputs from selected experts, weighted by the gating network, to produce the final model output.\n",
            "- Expert Training: Process of training each expert model on a subset of data or specific task aspects, independently.\n",
            "- Gating Network Training: Training the gating network to optimally combine experts' outputs based on input data.\n",
            "- Applications: MoE models are used in NLP, computer vision, speech recognition, and recommendation systems to improve accuracy and efficiency.\n",
            "\n",
            "Description: Mixture of Experts (MoE) is a machine learning framework that improves model performance by combining predictions from multiple specialized models, known as experts, using a gating network to dynamically select and weight their contributions.\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(summaries)):\n",
        "    print(f\"ARTICLE {i}\\n\")\n",
        "    print_summary(summaries[i])\n",
        "    print(\"\\n\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
